{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "'''\n",
    "Loading data\n",
    "'''\n",
    "start_dir = './tiny-imagenet-200/'\n",
    "\n",
    "#List all catgories\n",
    "imgCats = listdir(start_dir + 'train')\n",
    "catNum = len(imgCats)\n",
    "fileLocToNum = []\n",
    "catToLabelDict = {}\n",
    "\n",
    "#One-hot encoding\n",
    "for i in range(catNum):\n",
    "    catToLabelDict[imgCats[i]] = i\n",
    "    for img in listdir(start_dir + 'train/' + imgCats[i] + '/images'):\n",
    "        loc = start_dir + 'train/' + imgCats[i] + '/images/' + img\n",
    "        fileLocToNum.append((loc, i))\n",
    "        \n",
    "from random import shuffle \n",
    "shuffle(fileLocToNum)\n",
    "print(fileLocToNum[:10])\n",
    "\n",
    "\n",
    "class training_batch:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get(self):\n",
    "        while 1:\n",
    "            self.init_vars()\n",
    "            for i in fileLocToNum:\n",
    "                if(self.input_size < batch_size):\n",
    "                    self.read_image(i)\n",
    "                else:\n",
    "                    yield self.x_train, self.y_train\n",
    "                    self.init_vars()\n",
    "                    self.read_image(i)\n",
    "                self.input_size += 1\n",
    "            yield self.x_train, self.y_train # for last amount of data\n",
    "    \n",
    "    def init_vars(self):\n",
    "        self.input_size = 0\n",
    "        self.x_train = np.empty([batch_size, 64, 64, 3]).astype(np.float32)\n",
    "        self.y_train = np.empty([batch_size, catNum]).astype(np.float32)\n",
    "    \n",
    "    def read_image(self, i):\n",
    "        entry = i\n",
    "        img_arr = img_to_array(load_img(entry[0])) #channel first?\n",
    "        if(img_arr.shape != (64, 64, 3)):\n",
    "            img_arr = np.stack((img_arr, ) * 3)\n",
    "        self.x_train[self.input_size] = img_arr / 255\n",
    "        zeros = np.zeros(catNum)\n",
    "        zeros[entry[1]] = 1.0\n",
    "        self.y_train[self.input_size] = zeros\n",
    "\n",
    "input_shape = (64, 64, 3)\n",
    "\n",
    "class val_batch:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "            \n",
    "    def get(self):\n",
    "        f = open(start_dir + 'val/val_annotations.txt')\n",
    "        while 1:\n",
    "            self.init_vars()\n",
    "            for pic_cat in f.readlines():\n",
    "                #put into batch\n",
    "                if(self.input_size < batch_size):\n",
    "                    self.read_image(pic_cat.split())\n",
    "                else:\n",
    "                    yield self.x_val, self.y_val\n",
    "                    self.init_vars()\n",
    "                    self.read_image(pic_cat.split())\n",
    "                self.input_size += 1\n",
    "            yield self.x_val, self.y_val # for last amount of data\n",
    "        f.close()\n",
    "    \n",
    "    def init_vars(self):\n",
    "        self.input_size = 0\n",
    "        self.x_val = np.empty([batch_size, 64, 64, 3]).astype(np.float32)\n",
    "        self.y_val = np.empty([batch_size, catNum]).astype(np.float32)\n",
    "    \n",
    "    def read_image(self, i):\n",
    "        entry = i\n",
    "        file_name = entry[0]\n",
    "        cat = entry[1]\n",
    "        img_arr = img_to_array(load_img(start_dir + 'val/images/' + file_name))\n",
    "        if(img_arr.shape != (64, 64, 3)):\n",
    "            img_arr = np.stack((img_arr,) * 3) #change to 3-channel if black-white\n",
    "        self.x_val[self.input_size] = img_arr / 255\n",
    "        zeros = np.zeros(catNum)\n",
    "        zeros[catToLabelDict[cat]] = 1.0\n",
    "        self.y_val[self.input_size] = zeros\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(catNum))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = optimizer,\n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "def get_training_batch():\n",
    "    b = training_batch()\n",
    "    return b.get()\n",
    "\n",
    "def get_val_batch():\n",
    "    b = val_batch()\n",
    "    return b.get()\n",
    "\n",
    "model.fit_generator(get_training_batch(),\n",
    "                    steps_per_epoch = len(fileLocToNum) // batch_size + 1,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_data = get_val_batch(),\n",
    "                    validation_steps = 10000 // batch_size + 1)\n",
    "\n",
    "# Save model and weights\n",
    "save_dir = './'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, 'test')\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0) #沒test set 會爆\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_dir = './IMAGE_SET/train/train_data_batch_1'\n",
    "with open(file_dir, 'rb') as fo:\n",
    "    data = pickle.load(fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "(128116, 64, 64, 3)\n",
      " 169/2507 [=>............................] - ETA: 9:18 - loss: 16.0984 - acc: 0.0012"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4870e2b14642>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m                     \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_val_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                     validation_steps = 50000 // batch_size + 1)\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;31m# Save model and weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1154\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2075\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2076\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2077\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2078\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2079\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1796\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2332\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2333\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "#from keras import backend as K\n",
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "batch_size = 512\n",
    "num_class = 1000\n",
    "epochs = 50\n",
    "input_shape = (64, 64, 3)\n",
    "\n",
    "class batch:\n",
    "    def __init__(self, set_name):\n",
    "        self.dir = './IMAGE_SET/' + set_name + '/' #train or val\n",
    "        pass\n",
    "    \n",
    "    def __read_file(self):\n",
    "        for one_set in listdir(self.dir):\n",
    "            with open(self.dir + one_set, 'rb') as fo:\n",
    "                data = pickle.load(fo)\n",
    "                x = data['data']\n",
    "                y = data['labels']\n",
    "                del(data)\n",
    "                img_size = 64\n",
    "                img_size2 = pow(64, 2)\n",
    "                x = np.dstack((x[:, :img_size2], x[:, img_size2:2*img_size2], x[:, 2*img_size2:]))\n",
    "                x = x.reshape((x.shape[0], img_size, img_size, 3))\n",
    "                print(x.shape)\n",
    "                y = [i-1 for i in y] #shift index to start from 0\n",
    "                y = keras.utils.to_categorical(y, num_class)\n",
    "                yield x, y\n",
    "    \n",
    "    def get_batch(self):\n",
    "        for x_set, y_set in self.__read_file():\n",
    "            counter = 0\n",
    "            set_size = len(x_set)\n",
    "            while (counter + 1) * batch_size < set_size:\n",
    "                start = counter * batch_size\n",
    "                end = (counter + 1) * batch_size\n",
    "                yield x_set[start:end], y_set[start:end]\n",
    "                counter += 1\n",
    "            start = counter * batch_size\n",
    "            yield x_set[start:set_size], y_set[start:set_size]    \n",
    "    \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Conv2D(32, (3, 3)))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_class))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#optimizer = keras.optimizers.rmsprop(lr=0.001, decay=1e-5)\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=true). \n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = opt,\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "def get_training_batch():\n",
    "    b = batch('train')\n",
    "    return b.get_batch()\n",
    "\n",
    "def get_val_batch():\n",
    "    b = batch('val')\n",
    "    return b.get_batch()\n",
    "\n",
    "model.fit_generator(get_training_batch(),\n",
    "                    steps_per_epoch = 1281167 // batch_size + 5, ##等等改喔\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_data = get_val_batch(),\n",
    "                    validation_steps = 50000 // batch_size + 1)\n",
    "\n",
    "# Save model and weights\n",
    "save_dir = './'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, 'test')\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data['labels'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pow(64, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.arange(50)\n",
    "print(a)\n",
    "print(a[10:49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "with open('./IMAGE_SET/train/train_data_batch_1', 'rb') as fo:\n",
    "    data = pickle.load(fo)\n",
    "    x = data['data']\n",
    "    y = data['labels']\n",
    "    del(data)\n",
    "    img_size = 64\n",
    "    img_size2 = pow(64, 2)\n",
    "    x = np.dstack((x[:, :img_size2], x[:, img_size2:2*img_size2], x[:, 2*img_size2:]))\n",
    "    x = x.reshape((x.shape[0], img_size, img_size, 3))\n",
    "    y = [i-1 for i in y] #shift index to start from 0\n",
    "    \n",
    "    index = 8787\n",
    "    img = Image.fromarray(x[index])\n",
    "    print(y[index])\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1]\n",
      " [ 5.2]\n",
      " [ 5.3]\n",
      " [ 5.4]\n",
      " [ 5.5]\n",
      " [ 5.6]\n",
      " [ 5.7]\n",
      " [ 5.8]\n",
      " [ 5.9]\n",
      " [ 6. ]\n",
      " [ 6.1]\n",
      " [ 6.2]\n",
      " [ 6.3]\n",
      " [ 6.4]\n",
      " [ 6.5]\n",
      " [ 6.6]\n",
      " [ 6.7]\n",
      " [ 6.8]\n",
      " [ 6.9]\n",
      " [ 7. ]\n",
      " [ 7.1]\n",
      " [ 7.2]\n",
      " [ 7.3]\n",
      " [ 7.4]\n",
      " [ 7.5]\n",
      " [ 7.6]\n",
      " [ 7.7]\n",
      " [ 7.8]\n",
      " [ 7.9]\n",
      " [ 8. ]\n",
      " [ 8.1]\n",
      " [ 8.2]\n",
      " [ 8.3]\n",
      " [ 8.4]\n",
      " [ 8.5]\n",
      " [ 8.6]\n",
      " [ 8.7]\n",
      " [ 8.8]\n",
      " [ 8.9]\n",
      " [ 9. ]\n",
      " [ 9.1]\n",
      " [ 9.2]\n",
      " [ 9.3]\n",
      " [ 9.4]\n",
      " [ 9.5]\n",
      " [ 9.6]\n",
      " [ 9.7]\n",
      " [ 9.8]\n",
      " [ 9.9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.arange(100) * 0.1\n",
    "arg = np.argwhere(a > 5)\n",
    "print(a[arg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 8 7 1 2 3]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-7f7e4aa3e141>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#shift index to start from 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "y = [9,8,7,1,2,3]\n",
    "y = np.asarray(y)\n",
    "print(y)\n",
    "y = [i-1 for i in y] #shift index to start from 0\n",
    "train_args = np.argwhere(y < 5)\n",
    "print(y[train_args])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "start_dir = './tiny-imagenet-200/'\n",
    "\n",
    "#List all catgories\n",
    "imgCats = listdir(start_dir + 'train')\n",
    "catNum = len(imgCats)\n",
    "catToLabelDict = {}\n",
    "imgFileNameArray = []\n",
    "\n",
    "#One-hot encoding\n",
    "for i in range(catNum):\n",
    "    label = np.zeros(catNum).astype(np.float32)\n",
    "    label[i] = 1.0\n",
    "    catToLabelDict[imgCats[i]] = label\n",
    "    for img in listdir(start_dir + 'train/' + imgCats[i] + '/images'):\n",
    "        imgFileNameArray.append([imgCats[i], img]) #Put file name in array\n",
    "\n",
    "#Shuffle data\n",
    "imgFileNameArray = np.array(imgFileNameArray)\n",
    "rnd_order = np.arange(len(imgFileNameArray))\n",
    "np.random.shuffle(rnd_order)\n",
    "imgFileNameArray = imgFileNameArray[rnd_order]\n",
    "\n",
    "\n",
    "#Build batch\n",
    "BATCH_SIZE = 160\n",
    "x_batch = []\n",
    "y_batch = []\n",
    "\n",
    "counter = 0\n",
    "x_one_batch = []\n",
    "y_one_batch = []\n",
    "#make batch\n",
    "for i in range(len(imgFileNameArray)):\n",
    "    if counter < BATCH_SIZE:\n",
    "        x_one_batch.append(imgFileNameArray[i])\n",
    "        #print(imgFileNameArray[i])\n",
    "        y_one_batch.append(catToLabelDict[imgFileNameArray[i][0]])\n",
    "        counter += 1\n",
    "    else:        \n",
    "        x_batch.append(x_one_batch)\n",
    "        y_batch.append(y_one_batch)\n",
    "        #re-init\n",
    "        x_one_batch = []\n",
    "        y_one_batch = []\n",
    "        counter = 1\n",
    "        x_one_batch.append(imgFileNameArray[i])\n",
    "        y_one_batch.append(catToLabelDict[imgFileNameArray[i][0]])\n",
    "#append last batch\n",
    "x_batch.append(x_one_batch)\n",
    "y_batch.append(y_one_batch)\n",
    "#print(x_batch[0][0])\n",
    "\n",
    "set_size = 125 #read 125 batch in memory\n",
    "\n",
    "#actually read image\n",
    "def read_image(offset):\n",
    "    print('Reading images....')\n",
    "    image_set = np.zeros([set_size, BATCH_SIZE, 64, 64, 3]) #64*64*3 => image size\n",
    "    label_set = np.zeros([set_size, BATCH_SIZE, catNum]) #cats\n",
    "    for i in range(offset * set_size, (offset + 1) * set_size):\n",
    "        for batch_i in range(len(x_batch[i])):\n",
    "            batch_y = y_batch[batch_i] #xy have same length\n",
    "            img_dir = x_batch[i][batch_i]\n",
    "            img = Image.open(start_dir + 'train/' + img_dir[0] + '/images/' + img_dir[1])\n",
    "            img.load()\n",
    "            arr = np.asarray(img)\n",
    "            if(arr.shape == (64, 64)):\n",
    "                arr = np.stack((arr,) * 3, axis = -1) #change to 3-channel if black-white\n",
    "            image_set[i - offset * set_size][batch_i] = (arr - 128) / 255\n",
    "            label_set[i - offset * set_size] = batch_y\n",
    "    print('Finishing reading batch {0} to {1}'.format(offset * set_size, (offset + 1) * set_size - 1))\n",
    "    #print(image_set[0][0])\n",
    "    return image_set.astype(np.float32), label_set\n",
    "\n",
    "def read_val_image():\n",
    "    print('Reading validation images....')\n",
    "    image_set = []\n",
    "    label_set = []\n",
    "    f = open(start_dir + 'val/val_annotations.txt')\n",
    "    for pic_cat in f.readlines():\n",
    "        entry = pic_cat.split()\n",
    "        file_name = entry[0]\n",
    "        cat = entry[1]\n",
    "        img = Image.open(start_dir + 'val/images/' + file_name)\n",
    "        img.load()\n",
    "        arr = np.asarray(img)\n",
    "        if(arr.shape == (64, 64)):\n",
    "            arr = np.stack((arr,) * 3, axis = -1) #change to 3-channel if black-white\n",
    "        image_set.append((arr - 128) / 255)\n",
    "        label_set.append(catToLabelDict[cat])\n",
    "    \n",
    "    #do ???\n",
    "    image_set = np.split(np.asarray(image_set).astype(np.float32), 4)\n",
    "    label_set = np.split(np.asarray(label_set), 4)\n",
    "    print('Finishing reading validation images.')\n",
    "    return image_set, label_set\n",
    "\n",
    "#define nn\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    #print(shape)\n",
    "    #initial = tf.random_uniform(shape, minval = 0, maxval = 1, dtype=tf.float32)\n",
    "    #initial = np.ones(shape).astype(np.float32) * 0.1\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    #initial = tf.random_uniform(shape, minval = 0, maxval = 1, dtype=tf.float32)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def lrelu(x):\n",
    "    alpha = 0.1\n",
    "    return tf.maximum(x, alpha * x)\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 64, 64, 3]) # 64x64 image\n",
    "ys = tf.placeholder(tf.float32, [None, catNum])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "#x_image = tf.reshape(xs, [-1, 64, 64, 3]) #?? must edit\n",
    "\n",
    "filter_size = 5\n",
    "\n",
    "## conv1 layer ##\n",
    "W_conv1 = weight_variable([filter_size, filter_size, 3, 16]) # patch 3*3, in size 3, out size 32\n",
    "b_conv1 = bias_variable([16])\n",
    "#h_conv1 = tf.nn.relu(conv2d(xs, W_conv1) + b_conv1) # output size 64x64x32\n",
    "h_conv1 = lrelu(conv2d(xs, W_conv1) + b_conv1) # output size 64x64x32\n",
    "h_pool1 = max_pool_2x2(h_conv1)                                         # output size 32x32x32\n",
    "\n",
    "## conv2 layer ##\n",
    "W_conv2 = weight_variable([filter_size, filter_size, 16, 32]) # patch 5x5, in size 32, out size 64\n",
    "b_conv2 = bias_variable([32])\n",
    "#h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # output size 32x32x64\n",
    "h_conv2 = lrelu(conv2d(h_pool1, W_conv2) + b_conv2) # output size 32x32x64\n",
    "h_pool2 = max_pool_2x2(h_conv2)                                         # output size 16x16x64\n",
    "\n",
    "## conv3 layer ##\n",
    "W_conv3 = weight_variable([filter_size, filter_size, 32, 64]) # patch 5x5, in size 64, out size 128\n",
    "b_conv3 = bias_variable([64])\n",
    "#h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3) # output size 16x16x128\n",
    "h_conv3 = lrelu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "h_pool3 = max_pool_2x2(h_conv3)                                         # output size 8*8*128\n",
    "\n",
    "## fc1 layer ##\n",
    "W_fc1 = weight_variable([8 * 8 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool3_flat = tf.reshape(h_pool3, [-1, 8 * 8 * 64])\n",
    "#h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)\n",
    "h_fc1 = lrelu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "#h_fc1_drop = h_fc1\n",
    "\n",
    "## fc2 layer ##\n",
    "W_fc2 = weight_variable([1024, 512])\n",
    "b_fc2 = bias_variable([512])\n",
    "#h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "h_fc2 = lrelu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "#h_fc2_drop = h_fc2\n",
    "\n",
    "## fc3 layer ##\n",
    "W_fc3 = weight_variable([512, catNum])\n",
    "b_fc3 = bias_variable([catNum])\n",
    "fc3_logits = tf.matmul(h_fc2_drop, W_fc3) + b_fc3\n",
    "prediction = tf.nn.softmax(fc3_logits)\n",
    "\n",
    "# the error between prediction and real data\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1]))       # loss\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction)))\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = ys, logits = fc3_logits))\n",
    "train_step = tf.train.AdamOptimizer(0.01).minimize(cross_entropy)\n",
    "#train_step = tf.train.MomentumOptimizer(1e-2, 0.8).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(100):\n",
    "    for set_i in range(5): #等等改\n",
    "        image_set, label_set = read_image(set_i)\n",
    "        sum_loss = 0\n",
    "        for batch_i in range(len(image_set)):\n",
    "            #_, loss, dd1 = sess.run([train_step, cross_entropy, h_pool1], feed_dict={xs: image_set[batch_i], ys: label_set[batch_i], keep_prob: 0.5})\n",
    "            _, loss = sess.run([train_step, cross_entropy], feed_dict={xs: image_set[batch_i], ys: label_set[batch_i], keep_prob: 0.5})\n",
    "            sum_loss += loss\n",
    "            #print(sess.run(tf.reduce_sum(dd1)))\n",
    "        print('loss:', sum_loss / len(image_set))\n",
    "        #print(image_set[0][1][20][20])\n",
    "        #print('WC1:', dd1)\n",
    "        #print('BC1:', dd2)\n",
    "        del(image_set)\n",
    "        del(label_set)\n",
    "        \n",
    "        #Validate process\n",
    "        correct_num = 0\n",
    "        image_set, label_set = read_val_image()\n",
    "        for val_i in range(len(image_set)):\n",
    "            y_pre = sess.run(prediction, feed_dict={xs: image_set[val_i], keep_prob: 1}) #應該是這行就錯了\n",
    "            correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(label_set[val_i], 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            #result, d1, d2, d3, d4 = sess.run([accuracy, h_conv1, h_conv2, h_conv3, tf.argmax(y_pre, 1)], feed_dict={xs: image_set[val_i], ys: label_set[val_i], keep_prob: 1})\n",
    "            result = sess.run(accuracy, feed_dict={xs: image_set[val_i], ys: label_set[val_i], keep_prob: 1})\n",
    "            #print(y_pre[1])\n",
    "            #print(\"val:\", image_set[val_i][1][23][45])\n",
    "            #print(\"HC1:\", np.count_nonzero(d1) / d1.size)\n",
    "            #print(\"HC2:\", np.count_nonzero(d2) / d2.size)\n",
    "            #print(\"HC3:\", np.count_nonzero(d3) / d3.size)\n",
    "            print('Error rate:', (1 - result) * 100, '%')\n",
    "            #print('PRED:', d4)\n",
    "            #print('label_set:', d2)\n",
    "            \n",
    "        \"\"\"    \n",
    "        #for test what's going on\n",
    "        fake_data = np.ones((1, 64, 64 ,3)) * 128\n",
    "        y_f = sess.run([prediction, h_conv1, h_conv2, h_conv3], feed_dict={xs: fake_data, keep_prob: 1})\n",
    "        print(\"==========Fake data test==========\")\n",
    "        #print(\"PRED:\", y_f[0])\n",
    "        '''print(\"F3O:\", y_f[1])\n",
    "        print(\"F3W:\", y_f[2])\n",
    "        print(\"F3B:\", y_f[3])\n",
    "        print(\"F2W:\", y_f[4])\n",
    "        print(\"F2B:\", y_f[5])\n",
    "        print(\"F1W:\", y_f[6])\n",
    "        print(\"F1B:\", y_f[7])\n",
    "        print(\"C3W:\", y_f[8])\n",
    "        print(\"C3B:\", y_f[9])\n",
    "        print(\"C2W:\", y_f[10])\n",
    "        print(\"C2B:\", y_f[11])\n",
    "        print(\"C1W:\", y_f[12])\n",
    "        print(\"C1B:\", y_f[13])'''\n",
    "        print(\"HC1:\", np.count_nonzero(y_f[1]) / y_f[1].size)\n",
    "        print(\"HC2:\", np.count_nonzero(y_f[2]) / y_f[2].size)\n",
    "        print(\"HC3:\", np.count_nonzero(y_f[3]) / y_f[3].size)\n",
    "        print(\"==========Fake data test over==========\")\n",
    "        \"\"\"\n",
    "        \n",
    "        '''\n",
    "        for val_i in range(len(image_set)):\n",
    "            print(\"IMG:\", image_set[val_i][0][0][0])\n",
    "            pred = sess.run(prediction, feed_dict={xs: image_set[val_i]})\n",
    "            pred = pred.flatten()\n",
    "            print(\"PRED:\", pred[0])\n",
    "            #print(label_set[val_i].shape)\n",
    "            #print(tf.argmax(label_set[val_i]), tf.argmax(pred))\n",
    "            true_label, pred_label = sess.run([tf.argmax(label_set[val_i]), tf.argmax(pred)])\n",
    "            print(true_label, pred_label)\n",
    "            if(true_label == pred_label):\n",
    "                correct_num += 1\n",
    "            #print(correct_num, end = \" \")\n",
    "        print('error rate:', correct_num / len(image_set))\n",
    "        '''\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = {}\n",
    "a['hi'] = (19, 24)\n",
    "a['yo'] = (16, \"ggggg\")\n",
    "print(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = './tiny-imagenet-200/val/val_annotations.txt'\n",
    "f = open(loc)\n",
    "for p in f.readlines():\n",
    "    e = p.split()\n",
    "    print(e[0], e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "print(batch_xs[0])\n",
    "print(batch_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 8):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [[\"1\",\"2\"], [\"3\",\"4\"]]\n",
    "for b in a:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    return 123, 456\n",
    "\n",
    "a,b = 3,4\n",
    "with test() as w,h:\n",
    "    print(w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(64, 64, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.ones((1,3))\n",
    "print(a)\n",
    "print(np.atleast_3d(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "(20000, 64, 64, 3)\n",
      "(256, 64, 64, 3)\n",
      "(256, 64, 64, 3)\n",
      "(256, 64, 64, 3)\n",
      "(256, 64, 64, 3)\n",
      "(256, 64, 64, 3)\n",
      "(256, 64, 64, 3)\n",
      "(256, 64, 64, 3)\n",
      "(256, 64, 64, 3)\n",
      "(256, 64, 64, 3)\n",
      "(256, 64, 64, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_3 to have 2 dimensions, but got array with shape (256, 64, 64, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-09ecf09c8f1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    213\u001b[0m                     \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_val_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                     validation_steps = 10000 // batch_size + 1)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;31m# Save model and weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1221\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1223\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2112\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2113\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2114\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2116\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1824\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1826\u001b[1;33m             check_batch_axis=True)\n\u001b[0m\u001b[0;32m   1827\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1828\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1409\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1411\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1412\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1413\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    139\u001b[0m                                  \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                                  \u001b[1;34m' dimensions, but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                                  str(array.shape))\n\u001b[0m\u001b[0;32m    142\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_3 to have 2 dimensions, but got array with shape (256, 64, 64, 3)"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "'''\n",
    "Loading data\n",
    "'''\n",
    "start_dir = './tiny-imagenet-200/'\n",
    "\n",
    "#List all catgories\n",
    "imgCats = listdir(start_dir + 'train')\n",
    "catNum = len(imgCats)\n",
    "fileLocToNum = []\n",
    "catToLabelDict = {}\n",
    "\n",
    "#One-hot encoding\n",
    "for i in range(catNum):\n",
    "    catToLabelDict[imgCats[i]] = i\n",
    "    for img in listdir(start_dir + 'train/' + imgCats[i] + '/images'):\n",
    "        loc = start_dir + 'train/' + imgCats[i] + '/images/' + img\n",
    "        fileLocToNum.append((loc, i))\n",
    "        \n",
    "from random import shuffle \n",
    "shuffle(fileLocToNum)\n",
    "#print(fileLocToNum[:10])\n",
    "\n",
    "class training_batch:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __read_sample(self, file_dir, label):\n",
    "        img_arr = img_to_array(load_img(file_dir)) #channel first?\n",
    "        if(img_arr.shape != (64, 64, 3)):\n",
    "            img_arr = np.stack((img_arr, ) * 3)\n",
    "        zeros = np.zeros(catNum)\n",
    "        zeros[label] = 1.0\n",
    "        return img_arr, zeros\n",
    "    \n",
    "    def __read_part_file(self):\n",
    "        chunk_size = len(fileLocToNum) // 5\n",
    "        print(chunk_size)\n",
    "        for i in range(5):\n",
    "            x_chunk, y_chunk = [], []\n",
    "            for img_file in fileLocToNum[chunk_size * i:chunk_size * (i + 1)]:\n",
    "                x_sample, y_sample = self.__read_sample(img_file[0], img_file[1])\n",
    "                x_chunk.append(x_sample)\n",
    "                y_chunk.append(y_sample)\n",
    "            yield np.asarray(x_chunk), np.asarray(y_chunk)\n",
    "            \n",
    "    def __check_if_binary_built(self):\n",
    "        status = True\n",
    "        file_list = ['train.data.1.npy', 'train.data.2.npy', 'train.data.3.npy', \n",
    "                      'train.data.4.npy', 'train.data.5.npy', 'train.label.1.npy',\n",
    "                      'train.label.2.npy', 'train.label.3.npy', 'train.label.4.npy',\n",
    "                      'train.label.5.npy']\n",
    "        for file_name in file_list:\n",
    "            status = status and os.path.exists(start_dir + file_name)\n",
    "        return status\n",
    "    \n",
    "    def __build_binary(self):\n",
    "        i = 1\n",
    "        print('build_start')\n",
    "        for chunk_x, chunk_y in self.__read_part_file():\n",
    "            np.save(start_dir + 'train.data.' + str(i) + '.npy', chunk_x)\n",
    "            np.save(start_dir + 'train.label.' + str(i) + '.npy', chunk_x)\n",
    "            i += 1\n",
    "        print('build_finish')\n",
    "    \n",
    "    def get_batch(self):\n",
    "        if(self.__check_if_binary_built()):\n",
    "            while 1:\n",
    "                for i in range(5):\n",
    "                    chunk_x = np.load(start_dir + 'train.data.' + str(i + 1) + '.npy')\n",
    "                    chunk_y = np.load(start_dir + 'train.label.' + str(i + 1) + '.npy')\n",
    "                    counter  = 0\n",
    "                    chunk_size = chunk_x.shape[0]\n",
    "                    print(chunk_x.shape)\n",
    "                    while (counter + 1) * batch_size < chunk_size:\n",
    "                        start = counter * batch_size\n",
    "                        end = (counter + 1) * batch_size\n",
    "                        print(chunk_x[start:end].shape)\n",
    "                        yield chunk_x[start:end], chunk_y[start:end]\n",
    "                        counter += 1\n",
    "                    start = counter * batch_size\n",
    "                    yield chunk_x[start:chunk_size], chunk_y[start:chunk_size]\n",
    "        else:\n",
    "            self.__build_binary()\n",
    "            self.get_batch()\n",
    "\n",
    "class val_batch:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __read_sample(self, file_dir, label):\n",
    "        img_arr = img_to_array(load_img(file_dir)) #channel first?\n",
    "        if(img_arr.shape != (64, 64, 3)):\n",
    "            img_arr = np.stack((img_arr, ) * 3)\n",
    "        zeros = np.zeros(catNum)\n",
    "        zeros[label] = 1.0\n",
    "        return img_arr, zeros\n",
    "    \n",
    "    def __read_part_file(self):\n",
    "        f = open(start_dir + 'val/val_annotations.txt')\n",
    "        chunk_size = len(f.readlines())\n",
    "        x_chunk, y_chunk = [], []\n",
    "        for line in f.readlines():\n",
    "            lines = line.split()\n",
    "            file_dir = start_dir + 'val/images/' + lines[0]\n",
    "            label = catToLabelDict[lines[1]]\n",
    "            x_sample, y_sample = self.__read_sample(file_dir, label)\n",
    "            x_chunk.append(x_sample)\n",
    "            y_chunk.append(y_sample)\n",
    "        return np.asarray(x_chunk), np.asarray(y_chunk)\n",
    "            \n",
    "    def __check_if_binary_built(self):\n",
    "        status = True\n",
    "        file_list = ['val.data.1.npy', 'val.label.1.npy']\n",
    "        for file_name in file_list:\n",
    "            status = status and os.path.exists(start_dir + file_name)\n",
    "        return status\n",
    "    \n",
    "    def __build_binary(self):\n",
    "        i = 1\n",
    "        print('val_build_start')\n",
    "        for chunk_x, chunk_y in self.__read_part_file():\n",
    "            np.save(start_dir + 'val.data.' + str(i) + '.npy', chunk_x)\n",
    "            np.save(start_dir + 'val.label.' + str(i) + '.npy', chunk_x)\n",
    "            i += 1\n",
    "        print('val_build_finish')\n",
    "    \n",
    "    def get_batch(self):\n",
    "        if(self.__check_if_binary_built()):\n",
    "            while 1:\n",
    "                chunk_x = np.load(start_dir + 'val.data.1.npy')\n",
    "                chunk_y = np.load(start_dir + 'val.label.1.npy')\n",
    "                counter  = 0\n",
    "                chunk_size = chunk_x.shape[0]\n",
    "                print(chunk_x.shape)\n",
    "                while (counter + 1) * batch_size < chunk_size:\n",
    "                    start = counter * batch_size\n",
    "                    end = (counter + 1) * batch_size\n",
    "                    yield chunk_x[start:end], chunk_y[start:end]\n",
    "                    counter += 1\n",
    "                start = counter * batch_size\n",
    "                yield chunk_x[start:chunk_size], chunk_y[start:chunk_size]\n",
    "        else:\n",
    "            self.__build_binary()\n",
    "            self.get_batch()\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "input_shape = (64, 64, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64,(3, 3),padding='same',activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3,padding='same',activation='relu'))\n",
    "#model.add(Conv2D(128, kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "                 \n",
    "model.add(Conv2D(256,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(Conv2D(256,kernel_size=3,padding='same',activation='relu'))\n",
    "#model.add(Conv2D(256,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "                 \n",
    "model.add(Conv2D(128,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(Conv2D(128,kernel_size=3,padding='same',activation='relu'))\n",
    "#model.add(Conv2D(128,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))   \n",
    "                \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(catNum, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = optimizer,\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "def get_training_batch():\n",
    "    b = training_batch()\n",
    "    return b.get_batch()\n",
    "\n",
    "def get_val_batch():\n",
    "    b = val_batch()\n",
    "    return b.get_batch()\n",
    "\n",
    "model.fit_generator(get_training_batch(),\n",
    "                    steps_per_epoch = len(fileLocToNum) // batch_size + 1,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_data = get_val_batch(),\n",
    "                    validation_steps = 10000 // batch_size + 1)\n",
    "\n",
    "# Save model and weights\n",
    "save_dir = './'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, 'test')\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0) #沒test set 會爆\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 2.2754 - acc: 0.1270 - val_loss: 2.1270 - val_acc: 0.1817\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 2.0214 - acc: 0.2105 - val_loss: 1.8066 - val_acc: 0.3088\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 1.8194 - acc: 0.2934 - val_loss: 1.6539 - val_acc: 0.3611\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 1.6821 - acc: 0.3609 - val_loss: 1.5100 - val_acc: 0.4473\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 1.5476 - acc: 0.4267 - val_loss: 1.3288 - val_acc: 0.5154\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 1.4354 - acc: 0.4753 - val_loss: 1.2481 - val_acc: 0.5530\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 1.3495 - acc: 0.5143 - val_loss: 1.1428 - val_acc: 0.5844\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 1.2759 - acc: 0.5448 - val_loss: 1.0954 - val_acc: 0.5981\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 1.2116 - acc: 0.5681 - val_loss: 1.0552 - val_acc: 0.6168\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 1.1628 - acc: 0.5889 - val_loss: 0.9888 - val_acc: 0.6457\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 1.1134 - acc: 0.6040 - val_loss: 1.0284 - val_acc: 0.6428\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 1.0733 - acc: 0.6196 - val_loss: 0.9145 - val_acc: 0.6772\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 1.0337 - acc: 0.6393 - val_loss: 0.8797 - val_acc: 0.6933\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.9940 - acc: 0.6548 - val_loss: 0.8611 - val_acc: 0.7031\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.9635 - acc: 0.6627 - val_loss: 0.8344 - val_acc: 0.7046\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.9339 - acc: 0.6752 - val_loss: 0.8192 - val_acc: 0.7129\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.9064 - acc: 0.6858 - val_loss: 0.7758 - val_acc: 0.7294\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.8842 - acc: 0.6940 - val_loss: 0.7831 - val_acc: 0.7370\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.8697 - acc: 0.7011 - val_loss: 0.7333 - val_acc: 0.7486\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.8482 - acc: 0.7094 - val_loss: 0.7254 - val_acc: 0.7571\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.8280 - acc: 0.7173 - val_loss: 0.7038 - val_acc: 0.7594\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.8123 - acc: 0.7227 - val_loss: 0.6976 - val_acc: 0.7638\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.7986 - acc: 0.7254 - val_loss: 0.6740 - val_acc: 0.7759\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.7809 - acc: 0.7339 - val_loss: 0.6697 - val_acc: 0.7782\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.7709 - acc: 0.7376 - val_loss: 0.6884 - val_acc: 0.7715\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.7575 - acc: 0.7442 - val_loss: 0.7205 - val_acc: 0.7591\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.7439 - acc: 0.7485 - val_loss: 0.6656 - val_acc: 0.7772\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.7393 - acc: 0.7507 - val_loss: 0.6781 - val_acc: 0.7780\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.7253 - acc: 0.7557 - val_loss: 0.6384 - val_acc: 0.7845\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.7144 - acc: 0.7602 - val_loss: 0.6247 - val_acc: 0.7916\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.7068 - acc: 0.7623 - val_loss: 0.6237 - val_acc: 0.7981\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.7009 - acc: 0.7629 - val_loss: 0.6284 - val_acc: 0.7988\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.6874 - acc: 0.7695 - val_loss: 0.6732 - val_acc: 0.7844\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6745 - acc: 0.7737 - val_loss: 0.6077 - val_acc: 0.7986\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.6770 - acc: 0.7719 - val_loss: 0.6161 - val_acc: 0.7923\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.6685 - acc: 0.7750 - val_loss: 0.6737 - val_acc: 0.7758\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6546 - acc: 0.7801 - val_loss: 0.5633 - val_acc: 0.8164\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.6534 - acc: 0.7838 - val_loss: 0.6023 - val_acc: 0.8018\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6477 - acc: 0.7839 - val_loss: 0.5737 - val_acc: 0.8186\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6445 - acc: 0.7841 - val_loss: 0.5744 - val_acc: 0.8103\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.6405 - acc: 0.7845 - val_loss: 0.5899 - val_acc: 0.8117\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.6346 - acc: 0.7886 - val_loss: 0.5773 - val_acc: 0.8148\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.6278 - acc: 0.7892 - val_loss: 0.5841 - val_acc: 0.8094\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.6237 - acc: 0.7933 - val_loss: 0.5803 - val_acc: 0.8172\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6141 - acc: 0.7950 - val_loss: 0.5536 - val_acc: 0.8228\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6061 - acc: 0.7972 - val_loss: 0.5566 - val_acc: 0.8185\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.6060 - acc: 0.7979 - val_loss: 0.5474 - val_acc: 0.8212\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.6025 - acc: 0.7977 - val_loss: 0.5500 - val_acc: 0.8206\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.6022 - acc: 0.7975 - val_loss: 0.5611 - val_acc: 0.8195\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5956 - acc: 0.8008 - val_loss: 0.5473 - val_acc: 0.8256\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5925 - acc: 0.8038 - val_loss: 0.5505 - val_acc: 0.8237\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5830 - acc: 0.8055 - val_loss: 0.5510 - val_acc: 0.8230\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.5867 - acc: 0.8049 - val_loss: 0.5748 - val_acc: 0.8138\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5781 - acc: 0.8061 - val_loss: 0.5499 - val_acc: 0.8193\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5753 - acc: 0.8075 - val_loss: 0.5241 - val_acc: 0.8297\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5753 - acc: 0.8088 - val_loss: 0.5467 - val_acc: 0.8207\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5703 - acc: 0.8093 - val_loss: 0.5193 - val_acc: 0.8344\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5645 - acc: 0.8113 - val_loss: 0.5134 - val_acc: 0.8359\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5612 - acc: 0.8145 - val_loss: 0.5376 - val_acc: 0.8239\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5543 - acc: 0.8161 - val_loss: 0.5337 - val_acc: 0.8269\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5579 - acc: 0.8126 - val_loss: 0.5180 - val_acc: 0.8341\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5615 - acc: 0.8141 - val_loss: 0.5135 - val_acc: 0.8347\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5562 - acc: 0.8131 - val_loss: 0.5174 - val_acc: 0.8370\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5531 - acc: 0.8152 - val_loss: 0.5532 - val_acc: 0.8226\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5495 - acc: 0.8189 - val_loss: 0.5241 - val_acc: 0.8296\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5501 - acc: 0.8161 - val_loss: 0.5142 - val_acc: 0.8354\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.5412 - acc: 0.8205 - val_loss: 0.5120 - val_acc: 0.8344\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 0.5412 - acc: 0.8189 - val_loss: 0.5149 - val_acc: 0.8387\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 0.5412 - acc: 0.8222 - val_loss: 0.4975 - val_acc: 0.8384\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 0.5320 - acc: 0.8241 - val_loss: 0.5230 - val_acc: 0.8313\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.5380 - acc: 0.8232 - val_loss: 0.4967 - val_acc: 0.8347\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5346 - acc: 0.8213 - val_loss: 0.5024 - val_acc: 0.8403\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5310 - acc: 0.8252 - val_loss: 0.5177 - val_acc: 0.8336\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5278 - acc: 0.8255 - val_loss: 0.5180 - val_acc: 0.8351\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5239 - acc: 0.8274 - val_loss: 0.5012 - val_acc: 0.8390\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5221 - acc: 0.8279 - val_loss: 0.5227 - val_acc: 0.8356\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.5243 - acc: 0.8271 - val_loss: 0.4917 - val_acc: 0.8433\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5211 - acc: 0.8279 - val_loss: 0.4802 - val_acc: 0.8457\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5138 - acc: 0.8315 - val_loss: 0.5159 - val_acc: 0.8346\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5167 - acc: 0.8285 - val_loss: 0.5011 - val_acc: 0.8352\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5142 - acc: 0.8306 - val_loss: 0.4933 - val_acc: 0.8412\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5172 - acc: 0.8290 - val_loss: 0.4819 - val_acc: 0.8489\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.5062 - acc: 0.8321 - val_loss: 0.5003 - val_acc: 0.8372\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.5119 - acc: 0.8299 - val_loss: 0.4858 - val_acc: 0.8418\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5055 - acc: 0.8315 - val_loss: 0.4796 - val_acc: 0.8472\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.5031 - acc: 0.8339 - val_loss: 0.5068 - val_acc: 0.8359\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.5071 - acc: 0.8326 - val_loss: 0.4863 - val_acc: 0.8459\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.4985 - acc: 0.8343 - val_loss: 0.4686 - val_acc: 0.8483\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.4989 - acc: 0.8339 - val_loss: 0.4834 - val_acc: 0.8428\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.4986 - acc: 0.8342 - val_loss: 0.4801 - val_acc: 0.8458\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.4975 - acc: 0.8335 - val_loss: 0.4826 - val_acc: 0.8460\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.4945 - acc: 0.8364 - val_loss: 0.4994 - val_acc: 0.8453\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.4956 - acc: 0.8370 - val_loss: 0.4741 - val_acc: 0.8465\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.4956 - acc: 0.8355 - val_loss: 0.4879 - val_acc: 0.8469\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.4922 - acc: 0.8370 - val_loss: 0.4664 - val_acc: 0.8517\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.4885 - acc: 0.8369 - val_loss: 0.4638 - val_acc: 0.8484\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.4899 - acc: 0.8379 - val_loss: 0.4852 - val_acc: 0.8498\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.4808 - acc: 0.8399 - val_loss: 0.4667 - val_acc: 0.8510\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.4770 - acc: 0.8428 - val_loss: 0.4835 - val_acc: 0.8448\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.4854 - acc: 0.8398 - val_loss: 0.4795 - val_acc: 0.8429\n",
      "Saved trained model at E:\\TempWorkDir\\DEVICE\\saved_models\\keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 2s 192us/step\n",
      "Test loss: 0.479514657688\n",
      "Test accuracy: 0.8429\n"
     ]
    }
   ],
   "source": [
    "'''Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n",
    "(it's still underfitting at that point, though).\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "#opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.empty([0, 64, 64, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
